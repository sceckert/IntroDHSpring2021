# Homework 0

## Google and Ngrams

In his essay, "Data before the Fact," Daniel Rosenberg explores the history of the term "data" using something called "**n-grams**" and the **corpus**––a fancy word for a set or collection of files––of books digitized by Google. In this exercise, we're going to practice working with the GoogleNgram viewer to better understand some of the ways it might be used in research as well as some of the arguments that we can make *about* this tool.

1. Visit the [Google Ngram Viewer](https://books.google.com/ngrams).

2. Try to enter in "data."  What do you notice?

3. Try to change the dates to the parameters from Rosenberg's article?

4. Try one of Rosenberg's other search terms, "he sobbed" vs "she sobbed" or "zombie" vs "vambpire." What do you notice?

### What are we search when we search GoogleBooks?

5. Now change the corpus ––this is the collection of digitized books that the n-gram viewer searches–– from "English (2019)" to  "American English 2019" by selecting it from the dropdown men. What happened? What do you notice about the difference in the results? What implications might this have for the kind of arguments we can make with this data?

5. Change the corpus to "British English (2019)" and "English Fiction (2019)." What do you notice about the results displayed each time?

5. What *is* "British English (2019)" or "English Fiction (201())" do all of these corpuses?

- Find the section Google-Ngram Viewer's [information page](https://books.google.com/ngrams/info#) where these different corpuses are defined. How are they defined?  What implications does this have?

6. Finally, write up a few sentence reflectng on what you've found. You can include screenshots of your exploratory research with the Ngram Viewer if that helps. 


## ECCO 

Rosenberg doesn't just use the Google Ngram Viewer and Google Books. Where else does Rosenberg look in order to research the use of "data" in the eras before the 19th century?

1. Just to get our feet wet, search "data" in[ Eighteenth-Century Collections Online (ECCO)] (log in using your PU ID). What might Rosenberg have to do to this data to make it so that he can make the queries that he makes? (You might look at one more recent project that has done this: the [ECCO TCT transcription project](https://github.com/Early-Modern-OCR/TCP-ECCO-texts))