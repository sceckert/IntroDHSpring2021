{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction to Python: pandas continued"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Today we're going to learn how to clean a tabular datasat, perform simple analysis , lice up our dataset into meaningful subsets, make simple data visualizations, and work with missing data.\n",
    "\n",
    "We're also going to practice working with **YOUR** datasets!\n",
    "\n",
    "- [1. Refresher: What is Pandas?](#Refresher:-What-is-Pandas?)\n",
    "    - [Using Pandas to clean tabular data](#Using-Pandas-to-clean-tabular-data)\n",
    "    - [Cheatsheet: Operations we can peform on DataFrames](#Cheatsheet:-Operations-we-can-peform-on-DataFrames)\n",
    "    - [Using Pandas to analyze data](#Using-Pandas-to-analyze-data)\n",
    "    - [**Exercise 1**: Finding out more about our dataset](#Exercise-1:-Finding-out-more-about-our-dataset) \n",
    "- [2: Make a simple data visualization](#2:-Make-a-simple-data-visualization) \n",
    "    - [**Exercise 2**: Making a visualization](#Exercise-2:-Making-a-visualization)\n",
    "    - [Making a time series plot](#Making-a-time-series-plot)\n",
    "- [**Exercise 3**: Working with your own dataset](#Exercise-3:-Working-with-your-own-dataset)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Refresher: What is Pandas?\n",
    "\n",
    "Remember that last week learned about **`pandas`**, a powerful Python library for working with tabular data. \n",
    "\n",
    "`pandas` will read in tabular data (ie, a spreadsheet in the form of a .CSV, .TSV file). This library can also work with data in slightly more complicated formats, like JSON files.\n",
    "\n",
    "When you read in a file, `pandas` creates a **DataFrame** -- this is a souped up spreadsheet or array. \n",
    "\n",
    "For a quick refresher, look back at [Introduction to Python (continued)](https://mybinder.org/v2/gh/sceckert/introdhspring2021/main?urlpath=lab/tree/_week4/introduction-to-python-continued.ipynb)\n",
    "\n",
    "![image](../_images/pusheen-computer.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, let's load in pandas and our dataset, the [Bellevue Almshouse Dataset](https://nyuirish.net/almshouse/the-almshouse-records/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd ## Here we're giving pandas the nickname `pd`\n",
    "pd.options.display.max_rows = 100\n",
    "\n",
    "# Let's load in our CSV file as a DataFrame and assign it to a variable called `bellevue_df`\n",
    "bellevue_df = pd.read_csv('../_datasets/bellevue_almshouse_modified.csv', parse_dates=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bellevue_df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using Pandas to clean tabular data\n",
    "\n",
    "### Rename columns\n",
    "\n",
    "Since so many of you brought this up in your homework, I thought we could try to rename some of the columns in our dataframe so that the variables better reflect the context.\n",
    "To rename columns in a dataframe, we use the `.rename()` method and the `columns=` parameter.\n",
    "\n",
    "Let's rename the \"disease\" column to \"disease_recorded.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bellevue_df.rename(columns={'disease': 'disease_recorded'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But this only temporarily changes the name of the variable. To permanently change it, we have to re-assign the variable `bellevue_df`, like so:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bellevue_df = bellevue_df.rename(columns={'disease': 'disease_recorded'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's take a peek inside:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bellevue_df.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alright! Let's do the same thing for the \"profession,\" \"gender,\" and \"children\" columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bellevue_df = bellevue_df.rename(columns={'profession': 'profession_recorded',\\\n",
    "                            'gender' : 'gender_recorded', 'children': 'children_recorded'})\n",
    "# Note: if a line of code gets too long and you want to make sure that you don't have to\n",
    "# scroll over to keep reading it, you can create a line break with a backslash \\\n",
    "# Jupyter will read the multiple lines as one continuous line of code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bellevue_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### üí° Pro Tip üí° \n",
    "> One of the handy things about working with data in `pandas` is that it allows you to manipulate data, replace missing values, add new columns, or drop columns --- all **without** touching the original CSV or text files that you're working with. This can be particularly handy for exploratory research and for making sure that you don't accidentally overwrite your data!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clean and Transform data values\n",
    "Remember the string methods we learned last week ‚Äì‚Äìhow you can use `.str.replace()` or `str.lower()` to transform values in a string of text? Well, the same methods can be applied to pandas DataFrame columns!!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, If we want to replace the gender columns‚Äôs single letter abbreviation for gender ('m'/'f') with ‚Äúman‚Äù / ‚Äúwoman‚Äù, we could use the `.str.replace()` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bellevue_df[\"gender_recorded\"] = bellevue_df[\"gender_recorded\"].str.replace('m', 'man')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bellevue_df[\"gender_recorded\"] = bellevue_df[\"gender_recorded\"].str.replace('w', 'woman')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cheatsheet: Operations we can peform on DataFrames\n",
    "\n",
    "### Using string methods to clean or transform data in columns: \n",
    "\n",
    "![image](../_images/pusheen-yarn.png)\n",
    "\n",
    "| **Pandas String Method** | **Explanation**                                                                                   |\n",
    "|:-------------:|:---------------------------------------------------------------------------------------------------:|\n",
    "| df['column_name']`.str.lower()`         | makes the string in each row lowercase                                                                                |\n",
    "| df['column_name']`.str.upper()`         | makes the string in each row uppercase                                                |\n",
    "| df['column_name']`.str.title()`         | makes the string in each row titlecase                                                |\n",
    "| df['column_name']`.str.replace('old string', 'new string')`      | replaces `old string` with `new string` for each row |\n",
    "| df['column_name']`.str.contains('some string')`      | tests whether string in each row contains \"some string\" |\n",
    "| df['column_name']`.str.split('delim')`          | returns a list of substrings separated by the given delimiter |\n",
    "| df['column_name']`.str.join(list)`         | opposite of split(), joins the elements in the given list together using the string                                                                   \n",
    "\n",
    "\n",
    "### Renaming, adding, dropping columns\n",
    "![image](../_images/pusheen-bake.png)\n",
    "\n",
    "| Pandas operation | Explanation |\n",
    "| :--- |:--- |\n",
    "|df`.rename(columns={'old_name_of_column': 'new_name_of_column'})` | rename a column (or columns)|\n",
    "|df`.add(columns='name_of_column')`| add a column |\n",
    "|df`.drop(columns='name_of_column')`| drop a column |\n",
    "\n",
    "### Working with missing data\n",
    "![image](../_images/pusheen-detective.jpg)\n",
    "\n",
    "| Pandas operation | Explanation |\n",
    "| :--- | :--- |\n",
    "| df['column_name']`.isna()` |returns a True/False pairs for each row in a dataframe that is blank|\n",
    "| df['column_name']`.notna()` |returns a True/False pairs for each row in a dataframe that is **NOT** blank|\n",
    "| df['column_name']`.fillna()` | will allow you to fill in blank values with a new value |\n",
    "\n",
    "### Sorting, calculating, and `groupby()`\n",
    "![image](../_images/pusheen-typing.png)\n",
    "\n",
    "Note: some of these operations will only be able to run on certain data types (like integers and floats), while others, like `.count()` can help you generate quantitative data about a column of qualitative values (like the number of times a value appears).\n",
    "\n",
    "| Pandas operation | Explanation |\n",
    "| :--- | :--- |\n",
    "|df['column_name']`.count()`| gives you the number of observations, ie the number of rows with non-blank values|\n",
    "|df['column_name']`.value_counts()` | aggregates the data in a column and counts (cumulatively) each unique value |\n",
    "|df['column_name']`.sum()` | gives you the sum of values|\n",
    "|df['column_name']`.mean()` | gives you the mean of values in the column\n",
    "|df['column_name']`.median()`| median of values|\n",
    "|df['column_name']`.min()` | gives the minimum value in the column |\n",
    "|df['column_name']`.max()` |gives the maximum value in the column|\n",
    "|df['column_name']`.mode()`| gives the mode of the column |\n",
    "|df['column_name'].`std()`| gives the \"unbiased standard deviation\" - a statistical term for the estimated dispersion of values| \n",
    "|df`.describe(include='all')` | calculates the summary statistics for all columns of the dataframe|\n",
    "|df`.groupby('column_name')` | allows us to group data and perform calculations on the groups.|\n",
    "\n",
    "> Note! Pay attention to the difference in syntax between `.describe()`, `.groupby()` and other commands.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "____"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using Pandas to analyze data\n",
    "\n",
    "### Counting values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some of these commands we learned last week,when we used `.value_counts()` to look at the number of each value in the \"profession_recorded\" column and used the slice method (`[:10]`) to look at just the top 10:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bellevue_df['profession_recorded'].value_counts()[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Counting missing values\n",
    "\n",
    "The `.count()` method can also be applied to the DataFrame as a whole to count. Because `.count()` only counts a row with recorded data, we can combine it with the the `len()` function to get the percentage of each field with recorded data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To calculate the percentage of recorded data in each column of our dataframe\n",
    "bellevue_df.count() / len(bellevue_df) * 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filtering and sorting values\n",
    "\n",
    "We can combine some of these operations we've learned.\n",
    "\n",
    "What if we wanted to look at all entries with a particular value? We can filter our dataframe for particular values in particular columns.\n",
    "\n",
    "We type the name of the DataFrame `bellevue_df` followed by square brackets `[]` and then, instead of inserting a column name in our brackets, we insert a True/False condition. For example, to select only rows that contain the value ‚Äúcarpenter,‚Äù we insert the condition `bellevue_df['profession'] == 'carpenter'`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bellevue_df[bellevue_df['profession_recorded'] == \"carpenter\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can create a variable with the name of our filter. For instance, if we wanted to find all professions of women, we could first create a filter for women, assign it to a variable, and then select the \"professions\" in our new subset of data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a filter:\n",
    "bellevue_women = bellevue_df[bellevue_df['gender_recorded'] == 'w']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Then, let's check the contents of our filter\n",
    "bellevue_women"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's select the \"profession_recorded\" column, and tally our results with  `.value_counts()\n",
    "bellevue_women['profession_recorded'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Write to a CSV\n",
    "\n",
    "What if you want to save your output? There's a function for that! We can use the pands function `.to_csv` to write our output to a CSV file. \n",
    "\n",
    "Below, we‚Äôre also specifying that the encoding is utf-8 and that the Index (the bolded left-most column) is not included in the CSV file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bellevue_women.to_csv(\"Bellevue_women.csv\", encoding='utf-8', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using Groupby to generate statistics about your data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`.groupby()` is a useful tool for performing more complicated coomputations on your dataframe. If you've ever used a **\"pivot table\"** in Excel or GoogleSpreadsheets, It can be combined with other parameters. We can group all the  so that you can group all the columns in the dataframe by the values in one column, or we group only a subset  of columns. \n",
    "\n",
    "- `.groupby('column_name)['name_of_selected_columns_to_be_grouped']` : will group only the selected columns\n",
    "\n",
    "Ack! What does this mean? Let's say we wanted to group the whole dataframe by recorded gender, and count how many of the fields were recorded for each, we would type:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bellevue_df.groupby('gender_recorded').count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But if we wanted to know the median age of people, sorted by their recorded gender, we would type:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bellevue_df.groupby('gender_recorded')['age'].median()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 1: Finding out more about our dataset \n",
    "\n",
    "In the field below, use what you've learned in section, write  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. In the cell below, filter the dataframe to only include persons whose profession is \"teacher\"\n",
    "\n",
    "### !!! REMEMBER TO RUN THE CELLS ABOVE so you load in the CSV file and define variables!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. In the cell below, write the code that you would need to calculate the percentage of entries that contain no recorded data in the \"disease_recorded\" column? What is that percentage?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2: Make a simple data visualization "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can make some simple visualizations of what we've found!\n",
    "Run the cell below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bellevue_df['disease_recorded'].value_counts()[:10].plot(kind='bar', title='Bellevue Almshouse:\\nMost Frequent \"Diseases\" Recorded ') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Above, we used the `.plot()` function, and we used the parameter `kind=` to specify a bar chart. If we wanted to make it easier to read, we could flip the orientation to a horizontal chart:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bellevue_df['disease_recorded'].value_counts()[:10].plot(kind='barh', title='Bellevue Almshouse:\\nMost Frequent \"Diseases\" Recorded ') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Or we could make it a pie chart:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bellevue_df['disease_recorded'].value_counts()[:10].plot(kind='pie', title='Bellevue Almshouse:\\nMost Frequent \"Diseases\" Recorded ') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### ‚ÄºÔ∏è But wait --- what about all those ***blank spots*** that show up as NaN??\n",
    "\n",
    "Plotting functions in Python will ignore blank values. So all of those blank columns are ignored.\n",
    "\n",
    "We can try and make these blank spots a little more descriptive, much like we did for our simpler lists! \n",
    "\n",
    "\n",
    "### `.isna()` , `.notna()`, and `.fillna()`\n",
    "For dataframes, there are ways of sorting through missing data. These operations are called `.isna()` `.notna()` and `.fillna()`, which allow us to check if a value is NaN (or not), and to fill in blank values in a dataframe or in a section of a dataframe (like a column)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new column caled `disease_updated` that fills in all the blank spots in our `disease` column with \n",
    "# \"no disease recorded\"\n",
    "bellevue_df['disease_recorded_updated'] = bellevue_df['disease_recorded'].fillna('no disease recorded')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bellevue_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And now let's try and plot again, this time, plotting the column of updated diseases:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bellevue_df['disease_recorded_updated'].value_counts()[:10].plot(kind='bar', title='Bellevue Almshouse:\\nMost Frequent \"Diseases\"') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 2: Making a visualization\n",
    "\n",
    "Let's try to explore another column of our dataset, professions. With a partner, try and outline the code you would have to write if you wanted to plot the top 10 professions:\n",
    "\n",
    "> Hint: Don't forget about missing data!\n",
    "\n",
    "> Are there persons in our dataset whose professions are not recorded? How might we capture that fact in our dataset and in our visualization?\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Making a time series plot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One of the things that makes the `.groupby()` function so powerful is that it lets us make use of values in one column to plot our data. This is especially useful when we have data that comes with well formatted dates, as this dataset does."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's tell pandas to make sure to treat the values in our \"date_in\" column as dates\n",
    "bellevue_df['date_in'] = bellevue_df['date_in'].apply(pd.to_datetime)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's create a list of all the rows where there is a value recorded for the category \"gender_recorded\", and let's group them by the date they entered the almshouse. \n",
    "\n",
    "We can use the .groupby() method. \n",
    "\n",
    "- We enclose the category we want to group by in parentheses\n",
    "- Then, if we want to filter out just a single column, or subset of column, we put those in brackets afterword. In this case, we don't want the values, but the number of times there is a recorded value for each date>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bellevue_df.groupby('date_in')['disease_recorded'].count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can then plot this. Click and run the cell below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bellevue_df.groupby('date_in')['disease_recorded'].count()\\\n",
    ".plot(title='Bellevue Almshouse: Number of Persons with Recorded \"Diseases\"')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's compare that to our udpated column that includes no blank values, so that we can get a sense of how many persons were recorded, versus how many were recorded."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bellevue_df.groupby('date_in')[['disease_recorded','disease_recorded_updated']].count()\\\n",
    ".plot(title='Bellevue Almshouse: Number of Persons with Recorded \"Diseases\" vs. total number admitted')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Your turn! Copy the text above and try plotting one of our columns, changing the variable and the plot title."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 3: Working with your own dataset\n",
    "\n",
    "Let's try some of what we've learned on a dataset of your choosing! In pairs, use the space below to load and examine your own dataset.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. In the cell below, rename the variable `name_of_your_dataframe`. \n",
    "2. Then, place your cursor at the end of the file path `\"../_datasets/\"` and hit the `tab` button. You should see a list of files‚Äì‚ÄìI've uploaded versions of the datasets that you all were working on. \n",
    "3. Choose your dataset. Make sure that you choose a file ending in `.csv`. (Not all the files in the \"_datasets\" directory are CSV files).\n",
    "\n",
    "> ***Note***: if you're using the billboard_lyrics data, you need to specify the encoding as encoding=\"ISO-8859-1\"  \n",
    "> ***Note***: Some of you might not see your dataset here, or see a CSV version of your data‚Äì‚Äìthis may be because your dataset from you biography is not. If you do want to work with XML data, there are things we can do to create a dataframe from this, but we need to do a little more work. If you're up for a bit of a challenge, read through the https://pypi.org/project/pandas-read-xml/. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "name_of_your_dataframe = pd.read_csv('../_datasets/')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 3a:\n",
    "\n",
    "Once you've loaded your dataset, use one of the methods we've learned to sort, select:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 3b:\n",
    "Now, try and make a simiple data visualization using your dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
